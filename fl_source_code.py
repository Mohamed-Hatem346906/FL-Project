# -*- coding: utf-8 -*-
"""FL-Source Code.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1l28zTeqevwbnzLI5KOvDXVRHfPauiWDh
"""

# Colab: Install dependencies
!pip install timm

import torch
from torchvision import datasets, transforms
from torch.utils.data import Subset, DataLoader, SubsetRandomSampler
import numpy as np
import random
import copy
import torch
import torch.nn as nn
import timm
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay
import torch.optim as optim
import os
from google.colab import drive
from collections import defaultdict
drive.mount('/content/drive', force_remount=True)

# Configuration
class Config:
    DATASET = 'CIFAR100'
    MODEL_NAME = 'vit_small_patch16_224'
    BATCH_SIZE = 64
    NUM_CLIENTS = 20
    IID = True
    NC = 10  # Classes per client for non-IID
    VAL_SPLIT = 0.1
    EPOCHS_CENTRALIZED = 50
    EPOCHS_FEDAVG = 50
    LOCAL_EPOCHS = 5
    LR = 0.03
    MOMENTUM = 0.9
    WEIGHT_DECAY = 5e-4
    SPARSE_RATIO = 0.5
    CLIENT_FRACTION = 0.1  # C=0.1 for FedAvg

# Constants
NUM_CLASSES = 100
DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'
CHECKPOINT_PATH = '/content/drive/MyDrive/checkpoint.pth'

import numpy as np
import torch
from torch.utils.data import Subset, DataLoader, SubsetRandomSampler
from torchvision import datasets, transforms

# Data Loading and Processing
def get_transforms():
    """Return train and test transformations for CIFAR-100"""
    transform_train = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.RandomHorizontalFlip(),
        transforms.RandomRotation(15),
        transforms.ToTensor(),
        transforms.Normalize(mean=(0.5071, 0.4867, 0.4408), std=(0.2675, 0.2565, 0.2761)),
    ])
    transform_test = transforms.Compose([
        transforms.Resize((224, 224)),
        transforms.ToTensor(),
        transforms.Normalize(mean=(0.5071, 0.4867, 0.4408), std=(0.2675, 0.2565, 0.2761)),
    ])
    return transform_train, transform_test

def split_dataset(dataset, val_split=0.1, seed=42):
    """Split dataset into training and validation subsets"""
    np.random.seed(seed)
    indices = np.arange(len(dataset))
    np.random.shuffle(indices)
    val_size = int(len(dataset) * val_split)
    val_indices = indices[:val_size]
    train_indices = indices[val_size:]
    return Subset(dataset, train_indices), Subset(dataset, val_indices)

def iid_shard(dataset, num_clients):
    """Create IID partitions of the dataset"""
    data_per_client = len(dataset) // num_clients
    indices = np.arange(len(dataset))
    np.random.shuffle(indices)
    return [indices[i*data_per_client:(i+1)*data_per_client] for i in range(num_clients)]

def noniid_shard(dataset, num_clients, nc=1):
    """Create non-IID partitions with nc classes per client"""
    # Handle both regular datasets and Subsets
    if isinstance(dataset, Subset):
        labels = np.array(dataset.dataset.targets)[dataset.indices]
    else:
        labels = np.array(dataset.targets)

    num_classes = len(np.unique(labels))
    idx_by_class = [np.where(labels == i)[0] for i in range(num_classes)]
    client_indices = [[] for _ in range(num_clients)]
    classes_per_client = [np.random.choice(num_classes, nc, replace=False)
                         for _ in range(num_clients)]

    for client_id, client_classes in enumerate(classes_per_client):
        for c in client_classes:
            # Distribute samples equally among clients for each class
            cnt = len(idx_by_class[c]) // num_clients
            chosen = idx_by_class[c][:cnt]
            idx_by_class[c] = idx_by_class[c][cnt:]
            client_indices[client_id].extend(chosen.tolist())

    return client_indices

def get_dataloaders(config, iid=True, nc=10):
    """Create dataloaders for federated learning setup"""
    transform_train, transform_test = get_transforms()

    # Load datasets
    trainset = datasets.CIFAR100(root='./data', train=True, download=True, transform=transform_train)
    testset = datasets.CIFAR100(root='./data', train=False, download=True, transform=transform_test)

    # Split into train and validation
    trainset, valset = split_dataset(trainset, val_split=config.VAL_SPLIT)

    # Create shards (IID or non-IID)
    shards = iid_shard(trainset, config.NUM_CLIENTS) if iid else noniid_shard(trainset, config.NUM_CLIENTS, nc)

    # Create client dataloaders
    clients_loaders = [
        DataLoader(
            trainset,
            batch_size=config.BATCH_SIZE,
            sampler=SubsetRandomSampler(idxs),
            num_workers=2,
            pin_memory=True
        ) for idxs in shards
    ]

    # Create validation and test dataloaders
    val_loader = DataLoader(
        valset,
        batch_size=config.BATCH_SIZE,
        shuffle=False,
        num_workers=2,
        pin_memory=True
    )

    test_loader = DataLoader(
        testset,
        batch_size=config.BATCH_SIZE,
        shuffle=False,
        num_workers=2,
        pin_memory=True
    )

    return clients_loaders, val_loader, test_loader

# Model Architecture
class ViTSmallDINO(nn.Module):
    def __init__(self, num_classes=100):
        super().__init__()
        self.backbone = timm.create_model('vit_small_patch16_224', pretrained=True)
        self.backbone.head = nn.Linear(self.backbone.head.in_features, num_classes)

    def forward(self, x):
        return self.backbone(x)

def get_model(num_classes=100, device='cuda'):
    model = ViTSmallDINO(num_classes=num_classes)
    return model.to(device)

# Federated Learning Utilities
def average_weights(weights_list):
    avg = copy.deepcopy(weights_list[0])
    for key in avg.keys():
        for i in range(1, len(weights_list)):
            avg[key] += weights_list[i][key]
        avg[key] = torch.div(avg[key], len(weights_list))
    return avg

def fedavg_round(model, clients_loaders, config, mask=None, device='cuda'):
    selected_clients = random.sample(range(len(clients_loaders)), max(1, int(config.NUM_CLIENTS * config.CLIENT_FRACTION)))
    weights = []

    for client_idx in selected_clients:
        local_model = copy.deepcopy(model)
        optimizer = torch.optim.SGD(
            local_model.parameters(),
            lr=config.LR,
            momentum=config.MOMENTUM,
            weight_decay=config.WEIGHT_DECAY
        )
        criterion = nn.CrossEntropyLoss()

        for _ in range(config.LOCAL_EPOCHS):
            train(local_model, clients_loaders[client_idx], optimizer, criterion, device, mask)

        weights.append(copy.deepcopy(local_model.state_dict()))
        del local_model
        torch.cuda.empty_cache()

    model.load_state_dict(average_weights(weights))
    return model

# Model Editing Utilities
def fisher_sensitivity(model, dataloader, device, num_samples=128):
    model.eval()
    grads = []
    criterion = nn.CrossEntropyLoss()

    for i, (x, y) in enumerate(dataloader):
        x, y = x.to(device), y.to(device)
        model.zero_grad()
        output = model(x)
        loss = criterion(output, y)
        loss.backward()
        grads.append([p.grad.detach().clone() for p in model.parameters()])
        if i * x.size(0) >= num_samples:
            break

    return [(torch.stack(params) ** 2).mean(dim=0) for params in zip(*grads)]

def calibrate_mask(model, dataloader, device, method="least-sensitive", sparsity=0.2, seed=42):
    torch.manual_seed(seed)
    fisher = fisher_sensitivity(model, dataloader, device)
    mask = []

    for param_fisher in fisher:
        param_flat = param_fisher.view(-1)
        k = int(param_flat.numel() * sparsity)

        if method == "least-sensitive":
            idx = torch.topk(param_flat, k, largest=False).indices
        elif method == "most-sensitive":
            idx = torch.topk(param_flat, k, largest=True).indices
        elif method == "low-magnitude":
            idx = torch.topk(param_flat.abs(), k, largest=False).indices
        elif method == "high-magnitude":
            idx = torch.topk(param_flat.abs(), k, largest=True).indices
        elif method == "random":
            idx = torch.randperm(param_flat.numel())[:k]
        else:
            raise ValueError("Unknown method")

        m = torch.zeros_like(param_flat)
        m[idx] = 1
        mask.append(m.view(param_fisher.size()))

    return mask

def hybrid_mask(model, dataloader, device, sparsity=0.5, alpha=0.5):
    fisher = fisher_sensitivity(model, dataloader, device)
    magnitude = [p.abs().detach() for p in model.parameters()]
    hybrid_mask = []

    for f, m in zip(fisher, magnitude):
        score = alpha * f + (1 - alpha) * m
        k = int(score.numel() * sparsity)
        idx = torch.topk(score.view(-1), k, largest=False).indices
        m = torch.zeros_like(score.view(-1))
        m[idx] = 1
        hybrid_mask.append(m.view(score.size()))

    return hybrid_mask

class SparseSGDM(optim.SGD):
    def __init__(self, params, lr=0.01, momentum=0, weight_decay=0, mask=None):
        super().__init__(params, lr=lr, momentum=momentum, weight_decay=weight_decay)
        self.mask = mask

    @torch.no_grad()
    def step(self, closure=None):
        loss = super().step(closure)
        if self.mask:
            for group in self.param_groups:
                for i, p in enumerate(group['params']):
                    if p.grad is not None and i < len(self.mask):
                        p.grad *= self.mask[i].to(p.grad.device)
        return loss

# Training and Evaluation
def train(model, loader, optimizer, criterion, device, mask=None):
    model.train()
    loss_sum, correct, total = 0, 0, 0

    for x, y in loader:
        x, y = x.to(device), y.to(device)
        optimizer.zero_grad()
        outputs = model(x)
        loss = criterion(outputs, y)
        loss.backward()

        if mask is not None and isinstance(optimizer, SparseSGDM):
            optimizer.mask = mask

        optimizer.step()

        loss_sum += loss.item() * y.size(0)
        _, pred = outputs.max(1)
        correct += (pred == y).sum().item()
        total += y.size(0)

    return loss_sum / total, correct / total

def evaluate(model, loader, criterion, device):
    model.eval()
    loss_sum, correct, total = 0, 0, 0

    with torch.no_grad():
        for x, y in loader:
            x, y = x.to(device), y.to(device)
            outputs = model(x)
            loss = criterion(outputs, y)
            loss_sum += loss.item() * y.size(0)
            _, pred = outputs.max(1)
            correct += (pred == y).sum().item()
            total += y.size(0)

    return loss_sum / total, correct / total

# Experiment Tracking
def save_checkpoint(model, optimizer, epoch, path):
    torch.save({
        'epoch': epoch,
        'model_state': model.state_dict(),
        'optimizer_state': optimizer.state_dict(),
    }, path)

def load_checkpoint(model, optimizer, path, device):
    checkpoint = torch.load(path, map_location=device)
    model.load_state_dict(checkpoint['model_state'])
    optimizer.load_state_dict(checkpoint['optimizer_state'])
    return checkpoint['epoch']

# Visualization
def plot_curves(train_loss, val_loss, train_acc, val_acc, save_path=None):
    plt.figure(figsize=(12, 5))

    # Loss plot
    plt.subplot(1, 2, 1)
    plt.plot(train_loss, label='Train Loss', marker='o', markersize=3)
    plt.plot(val_loss, label='Val Loss', marker='o', markersize=3)
    plt.xlabel('Epoch')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.title("Loss Curves")

    # Accuracy plot
    plt.subplot(1, 2, 2)
    plt.plot(train_acc, label='Train Acc', marker='o', markersize=3)
    plt.plot(val_acc, label='Val Acc', marker='o', markersize=3)
    plt.xlabel('Epoch')
    plt.ylabel('Accuracy')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.title("Accuracy Curves")

    plt.tight_layout()
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.show()

def plot_conf_matrix(model, loader, class_names, device, normalize='true', save_path=None):
    y_true, y_pred = [], []
    model.eval()

    with torch.no_grad():
        for x, y in loader:
            x, y = x.to(device), y.to(device)
            out = model(x)
            _, preds = out.max(1)
            y_true.extend(y.cpu().numpy())
            y_pred.extend(preds.cpu().numpy())

    cm = confusion_matrix(y_true, y_pred, normalize=normalize)
    disp = ConfusionMatrixDisplay(cm, display_labels=class_names)

    fig, ax = plt.subplots(figsize=(10, 10))
    disp.plot(ax=ax, xticks_rotation='vertical', cmap='Blues',
             values_format='.2f' if normalize else 'd')
    plt.title('Confusion Matrix')
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.show()

def visualize_predictions(model, loader, class_names, device, n=8, save_path=None):
    model.eval()
    images, labels, preds = [], [], []

    with torch.no_grad():
        for x, y in loader:
            x, y = x.to(device), y.to(device)
            out = model(x)
            _, pred = out.max(1)
            images.append(x.cpu())
            labels.append(y.cpu())
            preds.append(pred.cpu())
            if len(images) * x.size(0) >= n:
                break

    images = torch.cat(images)[:n]
    labels = torch.cat(labels)[:n]
    preds = torch.cat(preds)[:n]

    plt.figure(figsize=(15, 3))
    for i in range(n):
        plt.subplot(1, n, i + 1)
        img = images[i].permute(1, 2, 0).numpy()
        img = (img * np.array([0.2675, 0.2565, 0.2761])) + np.array([0.5071, 0.4867, 0.4408])
        img = np.clip(img, 0, 1)

        # Color coding for correct/incorrect predictions
        color = 'green' if labels[i] == preds[i] else 'red'
        plt.imshow(img)
        plt.title(f"T:{class_names[labels[i]]}\nP:{class_names[preds[i]]}",
                  color=color)
        plt.axis('off')

    plt.tight_layout()
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
    plt.show()

# Experimental Routines
def run_centralized_training():
    drive.mount('/content/drive')
    config = Config()
    CHECKPOINT_PATH = '/content/drive/MyDrive/checkpoint.pth'
    # Set seeds
    seed = 42
    torch.manual_seed(seed)
    np.random.seed(seed)
    random.seed(seed)

    # Load data
    clients_loaders, val_loader, test_loader = get_dataloaders(config)
    class_names = [str(i) for i in range(NUM_CLASSES)]

    # Initialize model
    model = get_model(NUM_CLASSES, DEVICE)
    optimizer = optim.SGD(model.parameters(), lr=config.LR, momentum=config.MOMENTUM, weight_decay=config.WEIGHT_DECAY)
    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=config.EPOCHS_CENTRALIZED)
    criterion = nn.CrossEntropyLoss()

    # Load checkpoint if exists
    if os.path.exists(CHECKPOINT_PATH):
        try:
            checkpoint = torch.load(CHECKPOINT_PATH)

            # Backward compatible loading
            model.load_state_dict(checkpoint['model_state_dict'])
            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
            start_epoch = checkpoint['epoch'] + 1  # Start from next epoch

            # Ensure metrics exist in checkpoint
            train_losses = checkpoint.get('train_losses', [])
            val_losses = checkpoint.get('val_losses', [])
            train_accs = checkpoint.get('train_accs', [])
            val_accs = checkpoint.get('val_accs', [])

            print(f"Resumed from epoch {checkpoint['epoch']} with {len(train_losses)} metrics")

            # Verify metrics integrity
            if len(train_losses) != checkpoint['epoch'] + 1:
                print("Warning: Metric length mismatch! Initializing fresh metrics")
                train_losses, val_losses, train_accs, val_accs = [], [], [], []

        except Exception as e:
            print(f"Checkpoint load error: {e}. Starting fresh")
            start_epoch = 0
            train_losses, val_losses, train_accs, val_accs = [], [], [], []
    else:
        start_epoch = 0
        train_losses, val_losses, train_accs, val_accs = [], [], [], []
        print("No checkpoint found - starting new training")

    # Training loop
    for epoch in range(start_epoch, config.EPOCHS_CENTRALIZED):
        trl, tra = train(model, clients_loaders[0], optimizer, criterion, DEVICE)
        vall, vala = evaluate(model, val_loader, criterion, DEVICE)

        train_losses.append(trl)
        val_losses.append(vall)
        train_accs.append(tra)
        val_accs.append(vala)

        scheduler.step()
        print(f"Epoch {epoch}: Train Loss {trl:.4f}, Val Loss {vall:.4f} | "
              f"Train Acc {tra:.3f}, Val Acc {vala:.3f}")

        # Enhanced checkpoint saving
        torch.save({
            'version': 2.0,  # Version identifier
            'epoch': epoch,
            'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(),
            'train_losses': train_losses,
            'val_losses': val_losses,
            'train_accs': train_accs,
            'val_accs': val_accs,
        }, CHECKPOINT_PATH)

    # Evaluation
    tloss, tacc = evaluate(model, test_loader, criterion, DEVICE)
    print(f"Final Test Accuracy: {tacc:.3f}")

    # Visualizations
    plot_curves(train_losses, val_losses, train_accs, val_accs,
               save_path='training_curves.png')
    plot_conf_matrix(model, test_loader, class_names, DEVICE,
                   save_path='confusion_matrix.png')
    visualize_predictions(model, test_loader, class_names, DEVICE, n=8,
                        save_path='predictions.png')

    return model, train_losses, val_losses, train_accs, val_accs

def run_fedavg_experiments():
    fedavg_CHECKPOINT_PATH = '/content/drive/MyDrive/fedavg_checkpoint.pth'
    config = Config()
    nc_values = [1, 5, 10, 50]
    local_epochs_values = [4, 8, 16]
    results = defaultdict(dict)

    clients_loaders, val_loader, test_loader = get_dataloaders(config)
    criterion = nn.CrossEntropyLoss()

    for nc in nc_values:
        for local_epochs in local_epochs_values:
            model = get_model(NUM_CLASSES, DEVICE)
            optimizer = optim.SGD(model.parameters(), lr=config.LR, momentum=config.MOMENTUM)

            if os.path.exists(fedavg_CHECKPOINT_PATH):
                start_round = load_checkpoint(model, optimizer, fedavg_CHECKPOINT_PATH, DEVICE)
                print(f"Resumed from round {start_round}")
            else:
                start_round = 0
                print("Starting new experiment")

            for r in range(start_round, config.EPOCHS_FEDAVG):
                model = fedavg_round(model, clients_loaders, config, device=DEVICE)

                if (r + 1) % 5 == 0:  # Save every 5 rounds
                    val_loss, val_acc = evaluate(model, val_loader, criterion, DEVICE)
                    print(f"Round {r+1}: Val Acc {val_acc:.3f}")
                    save_checkpoint(model, optimizer, r, fedavg_CHECKPOINT_PATH)

            test_loss, test_acc = evaluate(model, test_loader, criterion, DEVICE)
            results[nc][local_epochs] = test_acc
    return results

# ---------- Sparse Training Experiments ----------
def run_sparse_experiments():
    config = Config()
    methods = ['least-sensitive', 'most-sensitive', 'low-magnitude', 'high-magnitude', 'random', 'hybrid']
    sparsity_ratios = [0.1, 0.3, 0.5, 0.7, 0.9]
    results = []

    # Create dedicated checkpoint directory for sparse experiments
    SPARSE_CHECKPOINT_DIR = "/content/drive/MyDrive/sparse_checkpoints"
    os.makedirs(SPARSE_CHECKPOINT_DIR, exist_ok=True)

    clients_loaders, val_loader, test_loader = get_dataloaders(config)
    criterion = nn.CrossEntropyLoss()

    for method in methods:
        # Create subdirectory for each method
        method_dir = os.path.join(SPARSE_CHECKPOINT_DIR, method)
        os.makedirs(method_dir, exist_ok=True)

        for sparsity in sparsity_ratios:
            print(f"\nMethod: {method}, Sparsity: {sparsity}")
            ckpt_path = os.path.join(method_dir, f"sparsity_{sparsity}.pt")

            model = get_model(NUM_CLASSES, DEVICE)

            # Select mask function with correct arguments
            if method == 'hybrid':
                mask = hybrid_mask(model, clients_loaders[0], DEVICE, sparsity=sparsity, alpha=0.5)
            else:
                mask = calibrate_mask(model, clients_loaders[0], DEVICE, method=method, sparsity=sparsity)

            optimizer = SparseSGDM(model.parameters(), lr=config.LR, momentum=config.MOMENTUM,
                                 weight_decay=config.WEIGHT_DECAY, mask=mask)

            start_epoch = 0
            if os.path.exists(ckpt_path):
                start_epoch = load_checkpoint(model, optimizer, ckpt_path, DEVICE)
                print(f"Resumed from epoch {start_epoch}")

            for epoch in range(start_epoch, 5):
                trl, tra = train(model, clients_loaders[0], optimizer, criterion, DEVICE)
                vall, vala = evaluate(model, val_loader, criterion, DEVICE)
                print(f"Epoch {epoch}: Train Acc {tra:.3f}, Val Acc {vala:.3f}")
                save_checkpoint(model, optimizer, epoch, ckpt_path)

            tloss, tacc = evaluate(model, test_loader, criterion, DEVICE)
            print(f"Test Accuracy for method {method}, sparsity {sparsity}: {tacc:.3f}")
            results.append({'method': method, 'sparsity': sparsity, 'accuracy': tacc})

    return results


# ---------- Mask Overlap Analysis ----------
def analyze_mask_overlap():
    config = Config()

    # Create dedicated checkpoint directory for mask analysis
    MASK_CHECKPOINT_DIR = '/content/drive/MyDrive/mask_checkpoints'
    os.makedirs(MASK_CHECKPOINT_DIR, exist_ok=True)

    clients_loaders, val_loader, _ = get_dataloaders(config, iid=False, nc=config.NC)
    model = get_model(NUM_CLASSES, DEVICE)

    methods = ['least-sensitive', 'most-sensitive', 'low-magnitude', 'high-magnitude', 'random', 'hybrid']
    SPARSE_RATIO = [0.1, 0.3, 0.5, 0.7, 0.9]

    results = []
    layer_similarities = {}
    similarity_matrix = np.zeros((5, 5))  # Assuming 5 clients

    for method in methods:
        # Create subdirectory for each method
        method_dir = os.path.join(MASK_CHECKPOINT_DIR, method)
        os.makedirs(method_dir, exist_ok=True)

        for sparsity in SPARSE_RATIO:
            print(f"\nMethod: {method}, Sparsity: {sparsity}")
            ckpt_path = os.path.join(method_dir, f"sparsity_{sparsity}.pt")

            model = get_model(NUM_CLASSES, DEVICE)

            # Fill in the proper arguments for mask computation
            if method == 'hybrid':
                mask = hybrid_mask(model, clients_loaders[0], DEVICE, sparsity=sparsity, alpha=0.5)
            else:
                mask = calibrate_mask(model, clients_loaders[0], DEVICE, method=method, sparsity=sparsity)

            optimizer = SparseSGDM(model.parameters(), lr=config.LR, momentum=config.MOMENTUM,
                                 weight_decay=config.WEIGHT_DECAY, mask=mask)

            start_epoch = 0
            if os.path.exists(ckpt_path):
                start_epoch = load_checkpoint(model, optimizer, ckpt_path, DEVICE)
                print(f"Resumed from epoch {start_epoch}")

            for epoch in range(start_epoch, 5):
                trl, tra = train(model, clients_loaders[0], optimizer, nn.CrossEntropyLoss(), DEVICE)
                vall, vala = evaluate(model, val_loader, nn.CrossEntropyLoss(), DEVICE)
                print(f"Epoch {epoch}: Train Acc {tra:.3f}, Val Acc {vala:.3f}")
                save_checkpoint(model, optimizer, epoch, ckpt_path)

    # Optionally return or save results
    return results

run_centralized_training()

run_fedavg_experiments()

run_fedavg_experiments()

run_sparse_experiments()

analyze_mask_overlap()

run_centralized_training()